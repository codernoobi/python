# accuracy metrics for model evaluation.
# Evaluation metrics are used to explain the performance of a model.
# basically, we can compare the actual values and predicted values to calculate the accuracy of a regression model.

# Evaluation metrics provide a key role in the development of a model, as it provides insight to areas that require improvement.
# Mean Absolute Error (MAE), Mean Squared Error (MSE), and Root Mean Squared Error (RMSE). 
# In the context of regression, the error of the model is the difference between the data points and the trend line generated by the algorithm.
# Since there are multiple data points, an error can be determined in multiple ways.

# Mean absolute error is the mean of the absolute value of the errors.

# Mean Squared Error (MSE) is the mean of the squared error.
# It’s more popular than Mean absolute error because the focus is geared more towards large errors.

# Root Mean Squared Error (RMSE) is the square root of the mean squared error.
# This is one of the most popular of the evaluation metrics because Root Mean Squared Error is interpretable in the same units 
# as the response vector (or ‘y’ units) making it easy to relate its information.

# Relative Absolute Error (RAE), also known as Residual sum of square, where y-bar is a mean value of y, takes the total absolute error and 
# normalizes it by dividing by the total absolute error of the simple predictor.

# Relative Squared Error (RSE) is very similar to “Relative absolute error “, but is widely adopted by the data science community, 
# as it is used for calculating R-squared
# R-squared is not error, per se, but is a popular metric for the accuracy of your model.
# It represents how close the data values are to the fitted regression line.
# The higher the R-squared, the better the model fits your data.

# Each of these metrics can be used for quantifying of your prediction.
# The choice of metric completely depends on the type of model, your data type, and domain of knowledge.